{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3e3fb5-fb7f-45ec-8372-09a4eb547a25",
   "metadata": {
    "id": "4f3e3fb5-fb7f-45ec-8372-09a4eb547a25",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import itertools\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b6b39-d20d-4665-b187-53a438ec4c76",
   "metadata": {},
   "source": [
    "Disclaimer: due to hardware limitations, I had to train the model with an under sample from the dataset. The complete set would have been used otherwise, as well as further optimization of hyper parameters and aditional machine learning models (randomforest, svc), and also a recurrent neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8831b3d-e0fd-4065-8516-179c292d0240",
   "metadata": {},
   "source": [
    "Index:\n",
    "    1 - Data preprocesing\n",
    "    \n",
    "    2 - Looking for patterns and relations between fraudulent transactions\n",
    "    \n",
    "    3 - Training the models\n",
    "    \n",
    "    4 - Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0ed9fe-9b07-4708-87a5-af8fa6c0838f",
   "metadata": {
    "id": "ad0ed9fe-9b07-4708-87a5-af8fa6c0838f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Fraud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f039e847-ee6a-4bb7-bd54-6ebe1613de2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f039e847-ee6a-4bb7-bd54-6ebe1613de2e",
    "outputId": "c6007b26-fabd-4177-b57e-f37eddb46a16",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig',\n",
       "       'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud',\n",
       "       'isFlaggedFraud'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2a5995-e44a-4dfd-a1da-dfbea365fa63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "de2a5995-e44a-4dfd-a1da-dfbea365fa63",
    "outputId": "5772224d-5e71-4750-a536-7e67274a7fb5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "      <td>6.362620e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.433972e+02</td>\n",
       "      <td>1.798619e+05</td>\n",
       "      <td>8.338831e+05</td>\n",
       "      <td>8.551137e+05</td>\n",
       "      <td>1.100702e+06</td>\n",
       "      <td>1.224996e+06</td>\n",
       "      <td>1.290820e-03</td>\n",
       "      <td>2.514687e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.423320e+02</td>\n",
       "      <td>6.038582e+05</td>\n",
       "      <td>2.888243e+06</td>\n",
       "      <td>2.924049e+06</td>\n",
       "      <td>3.399180e+06</td>\n",
       "      <td>3.674129e+06</td>\n",
       "      <td>3.590480e-02</td>\n",
       "      <td>1.585775e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.560000e+02</td>\n",
       "      <td>1.338957e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.390000e+02</td>\n",
       "      <td>7.487194e+04</td>\n",
       "      <td>1.420800e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.327057e+05</td>\n",
       "      <td>2.146614e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.350000e+02</td>\n",
       "      <td>2.087215e+05</td>\n",
       "      <td>1.073152e+05</td>\n",
       "      <td>1.442584e+05</td>\n",
       "      <td>9.430367e+05</td>\n",
       "      <td>1.111909e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.430000e+02</td>\n",
       "      <td>9.244552e+07</td>\n",
       "      <td>5.958504e+07</td>\n",
       "      <td>4.958504e+07</td>\n",
       "      <td>3.560159e+08</td>\n",
       "      <td>3.561793e+08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               step        amount  oldbalanceOrg  newbalanceOrig  \\\n",
       "count  6.362620e+06  6.362620e+06   6.362620e+06    6.362620e+06   \n",
       "mean   2.433972e+02  1.798619e+05   8.338831e+05    8.551137e+05   \n",
       "std    1.423320e+02  6.038582e+05   2.888243e+06    2.924049e+06   \n",
       "min    1.000000e+00  0.000000e+00   0.000000e+00    0.000000e+00   \n",
       "25%    1.560000e+02  1.338957e+04   0.000000e+00    0.000000e+00   \n",
       "50%    2.390000e+02  7.487194e+04   1.420800e+04    0.000000e+00   \n",
       "75%    3.350000e+02  2.087215e+05   1.073152e+05    1.442584e+05   \n",
       "max    7.430000e+02  9.244552e+07   5.958504e+07    4.958504e+07   \n",
       "\n",
       "       oldbalanceDest  newbalanceDest       isFraud  isFlaggedFraud  \n",
       "count    6.362620e+06    6.362620e+06  6.362620e+06    6.362620e+06  \n",
       "mean     1.100702e+06    1.224996e+06  1.290820e-03    2.514687e-06  \n",
       "std      3.399180e+06    3.674129e+06  3.590480e-02    1.585775e-03  \n",
       "min      0.000000e+00    0.000000e+00  0.000000e+00    0.000000e+00  \n",
       "25%      0.000000e+00    0.000000e+00  0.000000e+00    0.000000e+00  \n",
       "50%      1.327057e+05    2.146614e+05  0.000000e+00    0.000000e+00  \n",
       "75%      9.430367e+05    1.111909e+06  0.000000e+00    0.000000e+00  \n",
       "max      3.560159e+08    3.561793e+08  1.000000e+00    1.000000e+00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76358b64-e06e-426d-b4df-b74e24dd92ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76358b64-e06e-426d-b4df-b74e24dd92ee",
    "outputId": "b8785722-589e-4c51-df7d-3d7216a3e801",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0.0\n",
      "1          0.0\n",
      "4          0.0\n",
      "5          0.0\n",
      "6          0.0\n",
      "          ... \n",
      "6362312    0.0\n",
      "6362314    0.0\n",
      "6362316    0.0\n",
      "6362318    0.0\n",
      "6362319    0.0\n",
      "Name: newbalanceDest, Length: 2151495, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filter rows that nameDest starts with 'M' (Merchant)\n",
    "merchant_rows = df[df['nameDest'].str.startswith('M')]\n",
    "\n",
    "print(merchant_rows['newbalanceDest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15bb96-d96b-421a-90ee-f218537df1cc",
   "metadata": {},
   "source": [
    "At first glance, the dataset had no missing values, so no null treatment was done. However, given that Merchant movements doesn't have meaningful information, all the M customers were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "973390ce-61e1-4690-a561-f3ba73f01904",
   "metadata": {
    "id": "973390ce-61e1-4690-a561-f3ba73f01904",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step              0\n",
       "type              0\n",
       "amount            0\n",
       "nameOrig          0\n",
       "oldbalanceOrg     0\n",
       "newbalanceOrig    0\n",
       "nameDest          0\n",
       "oldbalanceDest    0\n",
       "newbalanceDest    0\n",
       "isFraud           0\n",
       "isFlaggedFraud    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['nameDest'].str.startswith('M')]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8698a1f4-c92f-438e-97dc-3878cad9fbfe",
   "metadata": {
    "id": "8698a1f4-c92f-438e-97dc-3878cad9fbfe",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step              0\n",
       "type              0\n",
       "amount            0\n",
       "nameOrig          0\n",
       "oldbalanceOrg     0\n",
       "newbalanceOrig    0\n",
       "nameDest          0\n",
       "oldbalanceDest    0\n",
       "newbalanceDest    0\n",
       "isFraud           0\n",
       "isFlaggedFraud    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by='step')\n",
    "\n",
    "train_split = 575\n",
    "\n",
    "train = df[df['step'] <= train_split]\n",
    "test = df[df['step'] > train_split]\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b1cbf8-00e5-481f-a8de-586389802793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_8600\\1489182613.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['train_test'] = 1\n",
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_8600\\1489182613.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['train_test'] = 0\n"
     ]
    }
   ],
   "source": [
    "train['train_test'] = 1\n",
    "test['train_test'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c4e744-0c6b-4ef4-8214-b54b04f3902f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6c4e744-0c6b-4ef4-8214-b54b04f3902f",
    "outputId": "595dd020-a192-4419-dcf9-4725512fd1d9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values (1): 8213\n",
      "False values (0): 4202912\n"
     ]
    }
   ],
   "source": [
    "true_count = df['isFraud'].sum()\n",
    "false_count = len(df) - true_count\n",
    "\n",
    "print(f'True values (1): {true_count}')\n",
    "print(f'False values (0): {false_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f49bdd-e320-43cf-b6c7-0497a879cdca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_transformations(df):\n",
    "    categories = ['CASH_IN', 'CASH_OUT', 'TRANSFER', 'DEBIT']  # Lista de categorías conocidas\n",
    "    \n",
    "    # Reemplazamos cualquier categoría desconocida por 'PAYMENT' (o la categoría que desees)\n",
    "    df['type'] = df['type'].apply(lambda x: x if x in categories else 'PAYMENT')\n",
    "    \n",
    "    category_mapping = {'CASH_IN': 1, 'CASH_OUT': 2, 'TRANSFER': 3, 'DEBIT': 4}\n",
    "    \n",
    "    df['type_encoded'] = df['type'].map(category_mapping)\n",
    "    \n",
    "    numeric_columns = ['step', 'amount', \n",
    "                       'oldbalanceOrg', 'newbalanceOrig', \n",
    "                       'oldbalanceDest', 'newbalanceDest']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "    \n",
    "    df_encoded = df.drop(['type'], axis=1)\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "# Aplicar transformaciones a los conjuntos de datos\n",
    "training_final = apply_transformations(train.copy())\n",
    "test_final = apply_transformations(test.copy())\n",
    "\n",
    "\n",
    "\n",
    "numeric_columns = ['step', 'amount',\n",
    "                   'oldbalanceOrg', 'newbalanceOrig',\n",
    "                   'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = training_final.drop(['isFraud', 'nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1)\n",
    "X_train_scaled[numeric_columns] = scaler.fit_transform(X_train_scaled[numeric_columns])\n",
    "y_train = training_final['isFraud']\n",
    "X_train_scaled.columns = X_train_scaled.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ddf1d96-7632-451a-acf4-1866bc9b9194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set transactions: 4128735\n",
      "Test set transactions: 106766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Imputación y escalado\n",
    "preprocessor = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_scaled_imputed = preprocessor.fit_transform(X_train_scaled)\n",
    "\n",
    "# Sobremuestreo con SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.0075, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled_imputed, y_train)\n",
    "\n",
    "# Convertir a DataFrames\n",
    "X_train_resampled_df = pd.DataFrame(X_train_resampled, columns=X_train_scaled.columns)\n",
    "y_train_resampled_df = pd.Series(y_train_resampled, name='isFraud')\n",
    "\n",
    "# Crear conjunto de prueba\n",
    "X_test_scaled = test_final.drop(['isFraud', 'nameOrig', 'nameDest', 'isFlaggedFraud'], axis=1)\n",
    "X_test_scaled.columns = X_test_scaled.columns.astype(str)\n",
    "y_test = test_final['isFraud']\n",
    "\n",
    "# Mostrar información sobre el tamaño del conjunto de entrenamiento y prueba\n",
    "print(\"Train set transactions:\", X_train_resampled_df.shape[0])\n",
    "print(\"Test set transactions:\", X_test_scaled.shape[0])\n",
    "\n",
    "# Procesamiento por lotes para el conjunto de entrenamiento\n",
    "batch_size = 10000\n",
    "num_batches = len(X_train_resampled_df) // batch_size\n",
    "\n",
    "X_train_batches = []\n",
    "y_train_batches = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = (i + 1) * batch_size\n",
    "    X_batch = X_train_resampled_df.iloc[start_idx:end_idx, :]\n",
    "    y_batch = y_train_resampled_df.iloc[start_idx:end_idx]\n",
    "    X_train_batches.append(X_batch)\n",
    "    y_train_batches.append(y_batch)\n",
    "\n",
    "# Si hay un lote final con un tamaño menor que batch_size\n",
    "if len(X_train_resampled_df) % batch_size != 0:\n",
    "    X_batch = X_train_resampled_df.iloc[num_batches * batch_size:, :]\n",
    "    y_batch = y_train_resampled_df.iloc[num_batches * batch_size:]\n",
    "    X_train_batches.append(X_batch)\n",
    "    y_train_batches.append(y_batch)\n",
    "\n",
    "# Combinar todos los lotes\n",
    "X_train_final = pd.concat(X_train_batches)\n",
    "y_train_final = pd.concat(y_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_train: (4128735, 8)\n",
      "Forma de y_train: (4128735,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma de X_train:\", X_train_final.shape)\n",
    "print(\"Forma de y_train:\", y_train_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b3a2dbe-89cc-4036-9c82-2f29e02bd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Creación de secuencias de datos para el modelo LSTM\n",
    "def create_sequence_data(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i+sequence_length])\n",
    "        y.append(data[i+sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 3. Construcción del modelo LSTM\n",
    "def build_lstm_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.LSTM(50, return_sequences=True, input_shape=input_shape),\n",
    "            tf.keras.layers.LSTM(50, return_sequences=False),\n",
    "            tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 4. Entrenamiento del modelo LSTM\n",
    "def train_lstm_model(model, X_train, y_train, epochs):\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, verbose=1)\n",
    "    return history\n",
    "\n",
    "# 5. Visualización de resultados (opcional)\n",
    "def visualize_lstm_results(model, X_test, y_test, scaler):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Asegúrate de que y_pred tiene la misma cantidad de columnas que y_test\n",
    "    if y_pred.shape[1] != y_test.shape[1]:\n",
    "        y_pred = scaler.inverse_transform(y_pred.reshape(-1, 1))  # Ajusta la forma si es necesario\n",
    "        y_test = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    else:\n",
    "        y_pred = scaler.inverse_transform(y_pred)\n",
    "        y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test, label='Observado')\n",
    "    plt.plot(y_pred, label='Predicción', color='red')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Resultados del Modelo LSTM')\n",
    "    plt.show()\n",
    "\n",
    "# Modificaciones para usar tus datos\n",
    "sequence_length = 10  # Ajusta la longitud de la secuencia según tus necesidades\n",
    "X_train, y_train = create_sequence_data(X_train_final.values, sequence_length)\n",
    "X_test, y_test = create_sequence_data(X_test_scaled.values, sequence_length)\n",
    "\n",
    "# Ajustes para procesamiento por lotes\n",
    "batch_size = 10000  # Ajusta el tamaño del lote según tus necesidades\n",
    "epochs = 10  # Ajusta el número de épocas según tus necesidades\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "lstm_model = build_lstm_model(input_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_train: (4128725, 10, 8)\n",
      "Forma de y_train: (4128725, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma de X_train:\", X_train.shape)\n",
    "print(\"Forma de y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "413/413 [==============================] - 550s 1s/step - loss: 0.8239\n",
      "Epoch 2/10\n",
      "413/413 [==============================] - 544s 1s/step - loss: 0.8208\n",
      "Epoch 3/10\n",
      "413/413 [==============================] - 550s 1s/step - loss: 0.8199\n",
      "Epoch 4/10\n",
      "413/413 [==============================] - 541s 1s/step - loss: 0.8193\n",
      "Epoch 5/10\n",
      "413/413 [==============================] - 502s 1s/step - loss: 0.8189\n",
      "Epoch 6/10\n",
      "413/413 [==============================] - 481s 1s/step - loss: 0.8186\n",
      "Epoch 7/10\n",
      "413/413 [==============================] - 531s 1s/step - loss: 0.8184\n",
      "Epoch 8/10\n",
      "413/413 [==============================] - 548s 1s/step - loss: 0.8182\n",
      "Epoch 9/10\n",
      "413/413 [==============================] - 571s 1s/step - loss: 0.8180\n",
      "Epoch 10/10\n",
      "413/413 [==============================] - 500s 1s/step - loss: 0.8178\n"
     ]
    }
   ],
   "source": [
    "history = lstm_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualización de resultados (opcional)\n",
    "def visualize_lstm_results(model, X_test, y_test, scaler):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Asegúrate de que y_pred tiene la misma cantidad de columnas que y_test\n",
    "    if y_pred.shape[1] != y_test.shape[1]:\n",
    "        # Si las dimensiones no coinciden, ajusta directamente la forma de y_pred\n",
    "        y_pred = y_pred[:, :y_test.shape[1]]\n",
    "    \n",
    "    # Invierte la transformación solo para las columnas relevantes\n",
    "    y_pred[:, :] = scaler.inverse_transform(y_pred[:, :])\n",
    "    \n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test, label='Observado')\n",
    "    plt.plot(y_pred, label='Predicción', color='red')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Resultados del Modelo LSTM')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3337/3337 [==============================] - 20s 6ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (106756,1) doesn't match the broadcast shape (106756,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lucas\\Documents\\Programacion\\fraud_trans\\main_bank-rnn.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Visualización de resultados\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m visualize_lstm_results(lstm_model, X_test, y_test, scaler)\n",
      "\u001b[1;32mc:\\Users\\Lucas\\Documents\\Programacion\\fraud_trans\\main_bank-rnn.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m y_pred[:, :y_test\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Invierte la transformación solo para las columnas relevantes\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y_pred[:, :] \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49minverse_transform(y_pred[:, :])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m y_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(y_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m6\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\tenflow\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1066\u001b[0m, in \u001b[0;36mStandardScaler.inverse_transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1064\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_std:\n\u001b[1;32m-> 1066\u001b[0m         X \u001b[39m*\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_\n\u001b[0;32m   1067\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_mean:\n\u001b[0;32m   1068\u001b[0m         X \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (106756,1) doesn't match the broadcast shape (106756,6)"
     ]
    }
   ],
   "source": [
    "# Visualización de resultados\n",
    "visualize_lstm_results(lstm_model, X_test, y_test, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4470dc36-5216-4654-9783-ffcc6b9c47cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lucas\\Documents\\Programacion\\fraud_trans\\main_bank-rnn.ipynb Cell 20\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstatsmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtsa\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstatespace\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msarimax\u001b[39;00m \u001b[39mimport\u001b[39;00m SARIMAX\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Asumiendo que y_train_final es una serie temporal unidimensional\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m sarimax_model \u001b[39m=\u001b[39m SARIMAX(y_train_final, order\u001b[39m=\u001b[39m(p, d, q), seasonal_order\u001b[39m=\u001b[39m(P, D, Q, s))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m sarimax_results \u001b[39m=\u001b[39m sarimax_model\u001b[39m.\u001b[39mfit()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Realizar predicciones\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "# Crear secuencias para el conjunto de prueba\n",
    "X_test_sequences, y_test_sequences = create_sequence_data(X_test_scaled.values, sequence_length)\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Asumiendo que y_train_final es una serie temporal unidimensional\n",
    "sarimax_model = SARIMAX(y_train_final, order=(p, d, q), seasonal_order=(P, D, Q, s))\n",
    "sarimax_results = sarimax_model.fit()\n",
    "\n",
    "# Realizar predicciones\n",
    "sarimax_predictions = sarimax_results.get_forecast(steps=len(X_test_sequences))\n",
    "# Suponiendo que sarimax_predictions.values contiene las predicciones\n",
    "combined_predictions = np.concatenate([sarimax_predictions.values, lstm_predictions], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lucas\\tenflow\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 5. Guardar el modelo entrenado\n",
    "def save_model(model, filename):\n",
    "    model.save(filename)\n",
    "\n",
    "save_model(lstm_model, 'modelo_entrenado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    return tf.keras.models.load_model(filename)\n",
    "\n",
    "# Cargar el modelo en futuras sesiones\n",
    "loaded_model = load_model('modelo_entrenado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Lucas\\tenflow\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 10",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lucas\\Documents\\Programacion\\fraud_trans\\main_bank-rnn.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X34sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m loaded_model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39m\u001b[39mmodelo_entrenado.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X34sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Preparar los datos de prueba (puedes cargarlos de tu conjunto de datos)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X34sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m X_test, y_test \u001b[39m=\u001b[39m create_sequence_data(test, sequence_length)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X34sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Escalar los datos de prueba usando el mismo scaler utilizado durante el entrenamiento\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X34sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m X_test_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)\n",
      "\u001b[1;32mc:\\Users\\Lucas\\Documents\\Programacion\\fraud_trans\\main_bank-rnn.ipynb Cell 24\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data) \u001b[39m-\u001b[39m sequence_length):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     X\u001b[39m.\u001b[39mappend(data[i:i\u001b[39m+\u001b[39msequence_length])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     y\u001b[39m.\u001b[39mappend(data[i\u001b[39m+\u001b[39;49msequence_length])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lucas/Documents/Programacion/fraud_trans/main_bank-rnn.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(X), np\u001b[39m.\u001b[39marray(y)\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\tenflow\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\tenflow\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 10"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "# 7. Evaluación del modelo cargado\n",
    "def evaluate_model(model, X_test, y_test, scaler):\n",
    "    # Realiza predicciones en los datos de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Ajusta la forma de y_pred si es necesario\n",
    "    if y_pred.shape[1] != y_test.shape[1]:\n",
    "        # Si las dimensiones no coinciden, ajusta directamente la forma de y_pred\n",
    "        y_pred = y_pred[:, :y_test.shape[1]]\n",
    "\n",
    "    # Invierte la transformación solo para las columnas relevantes\n",
    "    y_pred_inverse = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    # Invierte la transformación de y_test\n",
    "    y_test_inverse = scaler.inverse_transform(y_test)\n",
    "\n",
    "    # Evalúa el rendimiento del modelo (puedes usar diferentes métricas según tu problema)\n",
    "    mse = mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "    print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "# Ejemplo de uso para evaluar el modelo cargado\n",
    "# Suponiendo que tienes un conjunto de prueba X_test y y_test\n",
    "# Puedes cargar el modelo entrenado y evaluar su rendimiento en los datos de prueba\n",
    "\n",
    "# Cargar el modelo\n",
    "loaded_model = load_model('modelo_entrenado.h5')\n",
    "\n",
    "# Preparar los datos de prueba (puedes cargarlos de tu conjunto de datos)\n",
    "X_test, y_test = create_sequence_data(test, sequence_length)\n",
    "\n",
    "# Escalar los datos de prueba usando el mismo scaler utilizado durante el entrenamiento\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Evaluar el modelo cargado\n",
    "evaluate_model(loaded_model, X_test_scaled, y_test, scaler)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
